{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13613080,
          "sourceType": "datasetVersion",
          "datasetId": 8651170
        },
        {
          "sourceId": 13760011,
          "sourceType": "datasetVersion",
          "datasetId": 8756315
        },
        {
          "sourceId": 13770274,
          "sourceType": "datasetVersion",
          "datasetId": 8764024
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cross-Encoder Reranker for Ontology Disambiguation\n",
        "# Training script for Google Colab\n",
        "\n",
        "# ============================================================================\n",
        "# 1. INSTALLATION\n",
        "# ============================================================================\n",
        "\n",
        "!pip install -q sentence-transformers accelerate"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-17T14:04:38.587885Z",
          "iopub.execute_input": "2025-11-17T14:04:38.588134Z",
          "iopub.status.idle": "2025-11-17T14:05:47.628320Z",
          "shell.execute_reply.started": "2025-11-17T14:04:38.588111Z",
          "shell.execute_reply": "2025-11-17T14:05:47.627594Z"
        },
        "id": "QRdu0nhobRLA",
        "outputId": "16c9e70d-f9ea-4724-8810-fe7a04c13181"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade \"libraft-cu12==25.6.*\" \"pylibraft-cu12==25.6.*\" \"rmm-cu12==25.6.*\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-17T14:12:30.808472Z",
          "iopub.execute_input": "2025-11-17T14:12:30.809083Z",
          "iopub.status.idle": "2025-11-17T14:12:38.886417Z",
          "shell.execute_reply.started": "2025-11-17T14:12:30.809057Z",
          "shell.execute_reply": "2025-11-17T14:12:38.885425Z"
        },
        "id": "jJsH4ITkbRLC",
        "outputId": "2775fc88-85d2-4bca-e3ab-f9087ea545a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting libraft-cu12==25.6.*\n  Downloading libraft_cu12-25.6.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\nCollecting pylibraft-cu12==25.6.*\n  Downloading pylibraft_cu12-25.6.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\nCollecting rmm-cu12==25.6.*\n  Downloading rmm_cu12-25.6.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: librmm-cu12==25.6.* in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.6.*) (25.6.0)\nRequirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.6.*) (12.4.5.8)\nRequirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.6.*) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.6.*) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.6.*) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12>=2.19 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.6.*) (2.21.5)\nRequirement already satisfied: rapids-logger==0.1.* in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.6.*) (0.1.1)\nRequirement already satisfied: cuda-python<13.0a0,>=12.6.2 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==25.6.*) (12.9.4)\nRequirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==25.6.*) (1.26.4)\nRequirement already satisfied: cuda-bindings~=12.9.4 in /usr/local/lib/python3.11/dist-packages (from cuda-python<13.0a0,>=12.6.2->pylibraft-cu12==25.6.*) (12.9.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->pylibraft-cu12==25.6.*) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->pylibraft-cu12==25.6.*) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->pylibraft-cu12==25.6.*) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->pylibraft-cu12==25.6.*) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->pylibraft-cu12==25.6.*) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->pylibraft-cu12==25.6.*) (2.4.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12->libraft-cu12==25.6.*) (12.4.127)\nRequirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.11/dist-packages (from cuda-bindings~=12.9.4->cuda-python<13.0a0,>=12.6.2->pylibraft-cu12==25.6.*) (1.3.2)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0a0,>=1.23->pylibraft-cu12==25.6.*) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0a0,>=1.23->pylibraft-cu12==25.6.*) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0a0,>=1.23->pylibraft-cu12==25.6.*) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0a0,>=1.23->pylibraft-cu12==25.6.*) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0a0,>=1.23->pylibraft-cu12==25.6.*) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0a0,>=1.23->pylibraft-cu12==25.6.*) (2024.2.0)\nDownloading libraft_cu12-25.6.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (22.0 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m22.0/22.0 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pylibraft_cu12-25.6.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (876 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m876.0/876.0 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rmm_cu12-25.6.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: libraft-cu12, rmm-cu12, pylibraft-cu12\n  Attempting uninstall: libraft-cu12\n    Found existing installation: libraft-cu12 25.2.0\n    Uninstalling libraft-cu12-25.2.0:\n      Successfully uninstalled libraft-cu12-25.2.0\n  Attempting uninstall: rmm-cu12\n    Found existing installation: rmm-cu12 25.2.0\n    Uninstalling rmm-cu12-25.2.0:\n      Successfully uninstalled rmm-cu12-25.2.0\n  Attempting uninstall: pylibraft-cu12\n    Found existing installation: pylibraft-cu12 25.2.0\n    Uninstalling pylibraft-cu12-25.2.0:\n      Successfully uninstalled pylibraft-cu12-25.2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nraft-dask-cu12 25.2.0 requires libraft-cu12==25.2.*, but you have libraft-cu12 25.6.0 which is incompatible.\nraft-dask-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 25.6.0 which is incompatible.\nlibcuml-cu12 25.2.1 requires libraft-cu12==25.2.*, but you have libraft-cu12 25.6.0 which is incompatible.\nlibcuvs-cu12 25.2.1 requires libraft-cu12==25.2.*, but you have libraft-cu12 25.6.0 which is incompatible.\ncuml-cu12 25.2.1 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 25.6.0 which is incompatible.\ncuml-cu12 25.2.1 requires rmm-cu12==25.2.*, but you have rmm-cu12 25.6.0 which is incompatible.\npylibcudf-cu12 25.2.2 requires rmm-cu12==25.2.*, but you have rmm-cu12 25.6.0 which is incompatible.\ncudf-cu12 25.2.2 requires rmm-cu12==25.2.*, but you have rmm-cu12 25.6.0 which is incompatible.\ncuvs-cu12 25.2.1 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 25.6.0 which is incompatible.\nucxx-cu12 0.42.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 25.6.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed libraft-cu12-25.6.0 pylibraft-cu12-25.6.0 rmm-cu12-25.6.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 2. IMPORTS\n",
        "# ============================================================================\n",
        "\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from sentence_transformers.cross_encoder import CrossEncoder, CrossEncoderTrainer\n",
        "from sentence_transformers.cross_encoder import losses\n",
        "from sentence_transformers.cross_encoder.training_args import CrossEncoderTrainingArguments\n",
        "from sentence_transformers.cross_encoder.evaluation import CEBinaryClassificationEvaluator\n",
        "from typing import Dict, List\n",
        "\n",
        "# ============================================================================\n",
        "# 3. LOAD DATA\n",
        "# ============================================================================\n",
        "\n",
        "def load_jsonl(file_path: str) -> List[Dict]:\n",
        "    \"\"\"Load JSONL file into a list of dictionaries.\"\"\"\n",
        "    data = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "# Load datasets\n",
        "print(\"Loading datasets...\")\n",
        "train_data = load_jsonl('/kaggle/input/reranker-training-data/train.jsonl')\n",
        "dev_data = load_jsonl('/kaggle/input/reranker-training-data/dev.jsonl')\n",
        "test_data = load_jsonl('/kaggle/input/reranker-training-data/test.jsonl')\n",
        "\n",
        "print(f\"Train samples: {len(train_data)}\")\n",
        "print(f\"Dev samples: {len(dev_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")\n",
        "\n",
        "# Display sample\n",
        "print(\"\\nSample training example:\")\n",
        "print(json.dumps(train_data[0], indent=2))\n",
        "\n",
        "# ============================================================================\n",
        "# 4. PREPARE DATASETS FOR CROSS-ENCODER\n",
        "# ============================================================================\n",
        "\n",
        "def prepare_cross_encoder_dataset(data: List[Dict]) -> Dataset:\n",
        "    \"\"\"\n",
        "    Convert raw data to cross-encoder format.\n",
        "\n",
        "    Each example should have:\n",
        "    - sentence1: query\n",
        "    - sentence2: candidate\n",
        "    - label: binary label (0 or 1)\n",
        "    \"\"\"\n",
        "    prepared_data = {\n",
        "        'sentence1': [],\n",
        "        'sentence2': [],\n",
        "        'label': []\n",
        "    }\n",
        "\n",
        "    for item in data:\n",
        "        prepared_data['sentence1'].append(item['query'])\n",
        "        prepared_data['sentence2'].append(item['candidate'])\n",
        "        prepared_data['label'].append(float(item['label']))  # Ensure float for BCE loss\n",
        "\n",
        "    return Dataset.from_dict(prepared_data)\n",
        "\n",
        "# Prepare datasets\n",
        "print(\"\\nPreparing datasets for cross-encoder training...\")\n",
        "train_dataset = prepare_cross_encoder_dataset(train_data)\n",
        "dev_dataset = prepare_cross_encoder_dataset(dev_data)\n",
        "test_dataset = prepare_cross_encoder_dataset(test_data)\n",
        "\n",
        "print(f\"Prepared train dataset: {len(train_dataset)} samples\")\n",
        "print(f\"Prepared dev dataset: {len(dev_dataset)} samples\")\n",
        "print(f\"Prepared test dataset: {len(test_dataset)} samples\")\n",
        "\n",
        "# Display prepared sample\n",
        "print(\"\\nPrepared sample:\")\n",
        "print(train_dataset[0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-17T14:13:07.629811Z",
          "iopub.execute_input": "2025-11-17T14:13:07.630625Z",
          "iopub.status.idle": "2025-11-17T14:13:34.514892Z",
          "shell.execute_reply.started": "2025-11-17T14:13:07.630581Z",
          "shell.execute_reply": "2025-11-17T14:13:34.514094Z"
        },
        "id": "BvZGw-nXbRLC",
        "outputId": "58ba2301-3821-428c-8052-dfe44a684e5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading datasets...\nTrain samples: 2401485\nDev samples: 132647\nTest samples: 134290\n\nSample training example:\n{\n  \"query\": \"cell_type: cDC1; tissue: tonsil; organism: Homo sapiens\",\n  \"candidate\": \"label: tonsil germinal center B cell; definition: Any germinal center B cell that is part of a tonsil.\",\n  \"candidate_id\": \"CL:2000006\",\n  \"correct_id\": \"CL:0000990\",\n  \"label\": 0,\n  \"retrieval_score\": 1.0,\n  \"retrieval_rank\": 0,\n  \"example_type\": \"hard_negative\"\n}\n\nPreparing datasets for cross-encoder training...\nPrepared train dataset: 2401485 samples\nPrepared dev dataset: 132647 samples\nPrepared test dataset: 134290 samples\n\nPrepared sample:\n{'sentence1': 'cell_type: cDC1; tissue: tonsil; organism: Homo sapiens', 'sentence2': 'label: tonsil germinal center B cell; definition: Any germinal center B cell that is part of a tonsil.', 'label': 0.0}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 5. INITIALIZE MODEL\n",
        "# ============================================================================\n",
        "print(\"\\nInitializing CrossEncoder model...\")\n",
        "model = CrossEncoder(\n",
        "    \"bioformers/bioformer-16L\",\n",
        "    num_labels=1,  # Binary classification (relevance score)\n",
        "    max_length=512,  # Maximum sequence length\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")\n",
        "print(f\"Model loaded on device: {model.device}\")\n",
        "print(f\"Model max length: {model.max_length}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 6. SETUP LOSS FUNCTION\n",
        "# ============================================================================\n",
        "# Binary Cross Entropy Loss for binary relevance prediction\n",
        "pos_weight = torch.tensor([5.0])  # Weight positives 5x more\n",
        "loss = losses.BinaryCrossEntropyLoss(model, pos_weight=pos_weight)\n",
        "print(f\"\\nUsing BinaryCrossEntropyLoss with pos_weight={pos_weight.item()}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 7. SETUP EVALUATOR\n",
        "# ============================================================================\n",
        "# Create evaluator for binary classification\n",
        "evaluator = CEBinaryClassificationEvaluator(\n",
        "    sentence_pairs=list(zip(dev_dataset['sentence1'], dev_dataset['sentence2'])),\n",
        "    labels=dev_dataset['label'],\n",
        "    name='dev'\n",
        ")\n",
        "print(\"Evaluator configured for development set\")\n",
        "\n",
        "# ============================================================================\n",
        "# 8. CONFIGURE TRAINING ARGUMENTS\n",
        "# ============================================================================\n",
        "training_args = CrossEncoderTrainingArguments(\n",
        "    output_dir=\"./results-new\",\n",
        "\n",
        "    # Training hyperparameters\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.1,\n",
        "\n",
        "    # Evaluation and saving\n",
        "    eval_strategy='steps',\n",
        "    eval_steps=500,\n",
        "    save_strategy='steps',\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='dev_f1',\n",
        "\n",
        "    # Optimization\n",
        "    fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
        "    gradient_accumulation_steps=1,\n",
        "    max_grad_norm=1.0,\n",
        "\n",
        "    # Logging\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    logging_first_step=True,\n",
        "    report_to='none',  # Change to 'wandb' or 'tensorboard' if needed\n",
        "\n",
        "    # Other settings\n",
        "    seed=42,\n",
        "    dataloader_drop_last=False,\n",
        ")\n",
        "\n",
        "print(\"\\nTraining arguments configured:\")\n",
        "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
        "print(f\"  FP16: {training_args.fp16}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-17T14:14:15.334741Z",
          "iopub.execute_input": "2025-11-17T14:14:15.335069Z",
          "iopub.status.idle": "2025-11-17T14:14:25.013728Z",
          "shell.execute_reply.started": "2025-11-17T14:14:15.335044Z",
          "shell.execute_reply": "2025-11-17T14:14:25.013037Z"
        },
        "colab": {
          "referenced_widgets": [
            "37ee9b3015c44cd2b67d4b061a106e7b",
            "15aaedfc8d2f4c1abfd684301f21f303",
            "e1b8f9a70268401398931b1d5034facb",
            "d904a557343c4b218a03586861260c2f",
            "0cabc7e01c2c4792b021d4afa737292a"
          ]
        },
        "id": "G03L8N53bRLD",
        "outputId": "1156579e-b5f1-4fd0-fcfe-d2f28ac9246f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nInitializing CrossEncoder model...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37ee9b3015c44cd2b67d4b061a106e7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15aaedfc8d2f4c1abfd684301f21f303"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bioformers/bioformer-16L and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1b8f9a70268401398931b1d5034facb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d904a557343c4b218a03586861260c2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cabc7e01c2c4792b021d4afa737292a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Model loaded on device: cuda:0\nModel max length: 512\n\nUsing BinaryCrossEntropyLoss with pos_weight=5.0\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_48/2773534198.py:26: DeprecationWarning: This evaluator has been deprecated in favor of the more general CrossEncoderClassificationEvaluator. Please use CrossEncoderClassificationEvaluator instead, which supports both binary and multi-class evaluation. It accepts approximately the same inputs as this evaluator.\n  evaluator = CEBinaryClassificationEvaluator(\nWARNING:sentence_transformers.training_args:Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Evaluator configured for development set\n\nTraining arguments configured:\n  Epochs: 3\n  Batch size: 32\n  Learning rate: 2e-05\n  FP16: True\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 9. CHECKPOINT CONFIGURATION (RESUME SUPPORT)\n",
        "# ============================================================================\n",
        "import os\n",
        "import torch\n",
        "\n",
        "checkpoint_dir = \"/kaggle/input/checkpoint-85500/\"\n",
        "print(f\"\\nCheckpoint directory: {checkpoint_dir}\")\n",
        "\n",
        "resume_from_checkpoint = None\n",
        "\n",
        "# Direct checkpoint file detection (flat checkpoint structure)\n",
        "model_file = os.path.join(checkpoint_dir, \"pytorch_model.bin\")\n",
        "safetensors_file = os.path.join(checkpoint_dir, \"model.safetensors\")\n",
        "\n",
        "if os.path.exists(model_file) or os.path.exists(safetensors_file):\n",
        "    resume_from_checkpoint = checkpoint_dir\n",
        "    print(f\"‚úì Found checkpoint: {checkpoint_dir}\")\n",
        "    print(\"  Will resume training from this checkpoint.\")\n",
        "else:ci\n",
        "    print(\"‚ÑπÔ∏è  No existing checkpoints found. Starting fresh training.\")\n",
        "\n",
        "# Enable RNG loading for HF checkpoints - GET TRUE ORIGINAL\n",
        "if resume_from_checkpoint:\n",
        "    # Get the TRUE original torch.load from torch.serialization\n",
        "    # This bypasses any previous patches that might be in memory\n",
        "    import torch.serialization\n",
        "    _true_original_load = torch.serialization.load\n",
        "\n",
        "    # Create wrapper that always uses the true original\n",
        "    def custom_torch_load(*args, **kwargs):\n",
        "        if 'weights_only' not in kwargs:\n",
        "            kwargs['weights_only'] = False\n",
        "        return _true_original_load(*args, **kwargs)\n",
        "\n",
        "    torch.load = custom_torch_load\n",
        "    print(\"‚úì Configured torch.load to support RNG state loading\")\n",
        "\n",
        "# ============================================================================\n",
        "# 10. CUSTOM EARLY STOPPING CALLBACK\n",
        "# ============================================================================\n",
        "from transformers import TrainerCallback\n",
        "\n",
        "class ManualEarlyStoppingCallback(TrainerCallback):\n",
        "    \"\"\"\n",
        "    Custom early stopping callback compatible with CrossEncoderTrainer.\n",
        "    Monitors dev_f1 metric and stops training if no improvement.\n",
        "    \"\"\"\n",
        "    def __init__(self, patience=3, threshold=0.01, metric_name='dev_f1'):\n",
        "        self.patience = patience\n",
        "        self.threshold = threshold\n",
        "        self.metric_name = metric_name\n",
        "        self.best_metric = None\n",
        "        self.patience_counter = 0\n",
        "        self.should_stop = False\n",
        "\n",
        "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
        "        \"\"\"Called after evaluation\"\"\"\n",
        "        if metrics is None:\n",
        "            return control\n",
        "\n",
        "        current_metric = metrics.get(self.metric_name)\n",
        "\n",
        "        if current_metric is None:\n",
        "            return control\n",
        "\n",
        "        # First evaluation\n",
        "        if self.best_metric is None:\n",
        "            self.best_metric = current_metric\n",
        "            print(f\"\\nüìä Initial {self.metric_name}: {current_metric:.4f}\")\n",
        "            return control\n",
        "\n",
        "        # Check for improvement\n",
        "        improvement = current_metric - self.best_metric\n",
        "\n",
        "        if improvement > self.threshold:\n",
        "            # Improved significantly\n",
        "            self.best_metric = current_metric\n",
        "            self.patience_counter = 0\n",
        "            print(f\"\\n‚úì {self.metric_name} improved to {current_metric:.4f} (+{improvement:.4f})\")\n",
        "        else:\n",
        "            # No significant improvement\n",
        "            self.patience_counter += 1\n",
        "            print(f\"\\n‚ö†Ô∏è  No improvement in {self.metric_name}: {current_metric:.4f} \"\n",
        "                  f\"(best: {self.best_metric:.4f}, patience: {self.patience_counter}/{self.patience})\")\n",
        "\n",
        "            if self.patience_counter >= self.patience:\n",
        "                print(f\"\\nüõë Early stopping triggered! No improvement for {self.patience} evaluations.\")\n",
        "                control.should_training_stop = True\n",
        "                self.should_stop = True\n",
        "\n",
        "        return control\n",
        "\n",
        "    def state(self):\n",
        "        \"\"\"Return callback state for checkpointing\"\"\"\n",
        "        return {\n",
        "            'best_metric': self.best_metric,\n",
        "            'patience_counter': self.patience_counter,\n",
        "        }\n",
        "\n",
        "    def load_state(self, state):\n",
        "        \"\"\"Load callback state from checkpoint\"\"\"\n",
        "        self.best_metric = state.get('best_metric')\n",
        "        self.patience_counter = state.get('patience_counter', 0)\n",
        "        print(f\"‚úì Restored early stopping state: best_metric={self.best_metric}, patience_counter={self.patience_counter}\")\n",
        "\n",
        "# Initialize early stopping callback\n",
        "early_stopping = ManualEarlyStoppingCallback(\n",
        "    patience=1,\n",
        "    threshold=0.0001,\n",
        "    metric_name='dev_f1'\n",
        ")\n",
        "\n",
        "print(\"‚úì Manual early stopping callback initialized\")\n",
        "print(f\"  Patience: 1 evaluations\")\n",
        "print(f\"  Threshold: 0.0001\")\n",
        "print(f\"  Metric: dev_f1\")\n",
        "\n",
        "# ============================================================================\n",
        "# 11. INITIALIZE TRAINER\n",
        "# ============================================================================\n",
        "trainer = CrossEncoderTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    loss=loss,\n",
        "    evaluator=evaluator,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "print(\"\\nTrainer initialized successfully\")\n",
        "\n",
        "# Restore early stopping state if resuming\n",
        "if resume_from_checkpoint:\n",
        "    # Try to load early stopping state from checkpoint\n",
        "    early_stopping_state_file = os.path.join(checkpoint_dir, \"early_stopping_state.json\")\n",
        "    if os.path.exists(early_stopping_state_file):\n",
        "        import json\n",
        "        with open(early_stopping_state_file, 'r') as f:\n",
        "            es_state = json.load(f)\n",
        "        early_stopping.load_state(es_state)\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è  No early stopping state found in checkpoint, starting fresh\")\n",
        "\n",
        "# ============================================================================\n",
        "# 12. TRAIN MODEL (WITH CHECKPOINT RESUME)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "if resume_from_checkpoint:\n",
        "    print(\"RESUMING TRAINING FROM CHECKPOINT\")\n",
        "    print(f\"Checkpoint: {resume_from_checkpoint}\")\n",
        "else:\n",
        "    print(\"STARTING TRAINING\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING COMPLETED\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Save early stopping state for future resume\n",
        "import json\n",
        "es_state_file = os.path.join(training_args.output_dir, \"early_stopping_state.json\")\n",
        "with open(es_state_file, 'w') as f:\n",
        "    json.dump(early_stopping.state(), f)\n",
        "print(f\"‚úì Early stopping state saved to {es_state_file}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 13. EVALUATE ON TEST SET\n",
        "# ============================================================================\n",
        "print(\"Evaluating on test set...\")\n",
        "\n",
        "test_evaluator = CEBinaryClassificationEvaluator(\n",
        "    sentence_pairs=list(zip(test_dataset['sentence1'], test_dataset['sentence2'])),\n",
        "    labels=test_dataset['label'],\n",
        "    name='test'\n",
        ")\n",
        "\n",
        "test_results = test_evaluator(model)\n",
        "\n",
        "print(\"\\nTest Set Results:\")\n",
        "for metric, value in test_results.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 14. SAVE MODEL\n",
        "# ============================================================================\n",
        "output_path = \"./ontology-reranker\"\n",
        "model.save_pretrained(output_path)\n",
        "print(f\"\\nModel saved to: {output_path}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-17T22:48:43.088903Z",
          "iopub.execute_input": "2025-11-17T22:48:43.089453Z",
          "execution_failed": "2025-11-18T02:04:36.733Z"
        },
        "id": "XncLH-gHbRLD",
        "outputId": "c5239b71-b78b-4fca-80ef-5d36177dc9e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nCheckpoint directory: /kaggle/input/checkpoint-85500/\n‚úì Found checkpoint: /kaggle/input/checkpoint-85500/\n  Will resume training from this checkpoint.\n‚úì Configured torch.load to support RNG state loading\n‚úì Manual early stopping callback initialized\n  Patience: 1 evaluations\n  Threshold: 0.0001\n  Metric: dev_f1\n\nTrainer initialized successfully\n‚ÑπÔ∏è  No early stopping state found in checkpoint, starting fresh\n\n================================================================================\nRESUMING TRAINING FROM CHECKPOINT\nCheckpoint: /kaggle/input/checkpoint-85500/\n================================================================================\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='90035' max='112572' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 90035/112572 3:15:51 < 16:13:43, 0.39 it/s, Epoch 2.40/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Dev Accuracy</th>\n      <th>Dev Accuracy Threshold</th>\n      <th>Dev F1</th>\n      <th>Dev F1 Threshold</th>\n      <th>Dev Precision</th>\n      <th>Dev Recall</th>\n      <th>Dev Average Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>86000</td>\n      <td>0.183400</td>\n      <td>0.230241</td>\n      <td>0.974685</td>\n      <td>0.975106</td>\n      <td>0.819161</td>\n      <td>0.951832</td>\n      <td>0.801594</td>\n      <td>0.837515</td>\n      <td>0.886336</td>\n    </tr>\n    <tr>\n      <td>86500</td>\n      <td>0.169300</td>\n      <td>0.208405</td>\n      <td>0.975047</td>\n      <td>0.960146</td>\n      <td>0.817809</td>\n      <td>0.924933</td>\n      <td>0.795648</td>\n      <td>0.841240</td>\n      <td>0.888710</td>\n    </tr>\n    <tr>\n      <td>87000</td>\n      <td>0.152500</td>\n      <td>0.234804</td>\n      <td>0.975559</td>\n      <td>0.957142</td>\n      <td>0.821792</td>\n      <td>0.806979</td>\n      <td>0.808590</td>\n      <td>0.835433</td>\n      <td>0.891693</td>\n    </tr>\n    <tr>\n      <td>87500</td>\n      <td>0.164600</td>\n      <td>0.232705</td>\n      <td>0.975484</td>\n      <td>0.969608</td>\n      <td>0.820313</td>\n      <td>0.947480</td>\n      <td>0.820313</td>\n      <td>0.820313</td>\n      <td>0.892611</td>\n    </tr>\n    <tr>\n      <td>88000</td>\n      <td>0.182300</td>\n      <td>0.241580</td>\n      <td>0.975597</td>\n      <td>0.982167</td>\n      <td>0.819810</td>\n      <td>0.816658</td>\n      <td>0.789607</td>\n      <td>0.852416</td>\n      <td>0.890503</td>\n    </tr>\n    <tr>\n      <td>88500</td>\n      <td>0.207000</td>\n      <td>0.220260</td>\n      <td>0.975544</td>\n      <td>0.969271</td>\n      <td>0.823629</td>\n      <td>0.930022</td>\n      <td>0.799423</td>\n      <td>0.849348</td>\n      <td>0.888866</td>\n    </tr>\n    <tr>\n      <td>89000</td>\n      <td>0.161100</td>\n      <td>0.304276</td>\n      <td>0.975702</td>\n      <td>0.967635</td>\n      <td>0.824336</td>\n      <td>0.608536</td>\n      <td>0.800268</td>\n      <td>0.849896</td>\n      <td>0.885386</td>\n    </tr>\n    <tr>\n      <td>89500</td>\n      <td>0.169700</td>\n      <td>0.225957</td>\n      <td>0.975423</td>\n      <td>0.957369</td>\n      <td>0.822275</td>\n      <td>0.845350</td>\n      <td>0.808601</td>\n      <td>0.836419</td>\n      <td>0.895673</td>\n    </tr>\n    <tr>\n      <td>90000</td>\n      <td>0.160800</td>\n      <td>0.223263</td>\n      <td>0.975544</td>\n      <td>0.960353</td>\n      <td>0.815986</td>\n      <td>0.903579</td>\n      <td>0.812134</td>\n      <td>0.819875</td>\n      <td>0.889527</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 14. INFERENCE EXAMPLE\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"INFERENCE EXAMPLE\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Load saved model (optional - for demonstration)\n",
        "# loaded_model = CrossEncoder(output_path)\n",
        "\n",
        "# Example inference\n",
        "example_query = \"cell_type: C_BEST4; tissue: descending colon; organism: Homo sapiens\"\n",
        "example_candidates = [\n",
        "    \"label: smooth muscle fiber of descending colon; synonyms: non-striated muscle fiber of descending colon; definition: A smooth muscle cell that is part of the descending colon.\",\n",
        "    \"label: smooth muscle cell of colon; synonyms: non-striated muscle fiber of colon; definition: A smooth muscle cell that is part of the colon.\",\n",
        "    \"label: epithelial cell of colon; synonyms: colon epithelial cell; definition: An epithelial cell that is part of the colon.\"\n",
        "]\n",
        "\n",
        "print(\"Query:\")\n",
        "print(f\"  {example_query}\\n\")\n",
        "\n",
        "print(\"Ranking candidates...\")\n",
        "# Create pairs\n",
        "pairs = [(example_query, candidate) for candidate in example_candidates]\n",
        "\n",
        "# Get predictions\n",
        "scores = model.predict(pairs)\n",
        "\n",
        "# Rank by score\n",
        "ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
        "\n",
        "print(\"\\nRanked Results:\")\n",
        "for rank, idx in enumerate(ranked_indices, 1):\n",
        "    print(f\"\\n{rank}. Score: {scores[idx]:.4f}\")\n",
        "    print(f\"   Candidate: {example_candidates[idx][:100]}...\")\n",
        "\n",
        "# ============================================================================\n",
        "# 15. BATCH RANKING EXAMPLE\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BATCH RANKING WITH model.rank()\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Using the convenient rank() method\n",
        "ranked_results = model.rank(\n",
        "    example_query,\n",
        "    example_candidates,\n",
        "    return_documents=True,\n",
        "    top_k=3\n",
        ")\n",
        "\n",
        "print(\"Top 3 ranked results using model.rank():\")\n",
        "for result in ranked_results:\n",
        "    print(f\"\\nRank: {result['corpus_id'] + 1}\")\n",
        "    print(f\"Score: {result['score']:.4f}\")\n",
        "    print(f\"Text: {result['text'][:100]}...\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SCRIPT COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-17T22:48:40.611739Z",
          "iopub.status.idle": "2025-11-17T22:48:40.612049Z",
          "shell.execute_reply.started": "2025-11-17T22:48:40.611906Z",
          "shell.execute_reply": "2025-11-17T22:48:40.611920Z"
        },
        "id": "pJhTJl9kbRLE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# INFERENCE USING CHECKPOINT MODEL\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "\n",
        "checkpoint_path = \"/kaggle/input/checkpoint-78500/\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"INFERENCE EXAMPLE\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Load saved model from checkpoint\n",
        "loaded_model = CrossEncoder(checkpoint_path, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Example inference\n",
        "example_query = \"cell_type: C_BEST4; tissue: descending colon; organism: Homo sapiens\"\n",
        "example_candidates = [\n",
        "    \"label: smooth muscle fiber of descending colon; synonyms: non-striated muscle fiber of descending colon; definition: A smooth muscle cell that is part of the descending colon.\",\n",
        "    \"label: smooth muscle cell of colon; synonyms: non-striated muscle fiber of colon; definition: A smooth muscle cell that is part of the colon.\",\n",
        "    \"label: epithelial cell of colon; synonyms: colon epithelial cell; definition: An epithelial cell that is part of the colon.\"\n",
        "]\n",
        "\n",
        "print(\"Query:\")\n",
        "print(f\"  {example_query}\\n\")\n",
        "\n",
        "print(\"Ranking candidates...\")\n",
        "# Create pairs\n",
        "pairs = [(example_query, candidate) for candidate in example_candidates]\n",
        "\n",
        "# Get predictions (raw logits)\n",
        "raw_scores = loaded_model.predict(pairs)\n",
        "\n",
        "# Convert to probabilities (0-1) using sigmoid\n",
        "import torch.nn.functional as F\n",
        "scores = torch.sigmoid(torch.tensor(raw_scores)).numpy()\n",
        "\n",
        "# Rank by score\n",
        "ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
        "\n",
        "print(\"\\nRanked Results:\")\n",
        "for rank, idx in enumerate(ranked_indices, 1):\n",
        "    print(f\"\\n{rank}. Probability: {scores[idx]:.4f}\")\n",
        "    print(f\"   Candidate: {example_candidates[idx]}\")\n",
        "\n",
        "# ============================================================================\n",
        "# BATCH RANKING EXAMPLE\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BATCH RANKING WITH model.rank()\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Using the convenient rank() method\n",
        "ranked_results = loaded_model.rank(\n",
        "    example_query,\n",
        "    example_candidates,\n",
        "    return_documents=True,\n",
        "    top_k=3\n",
        ")\n",
        "\n",
        "print(\"Top 3 ranked results using model.rank():\")\n",
        "for result in ranked_results:\n",
        "    # Convert score to probability if needed\n",
        "    prob = torch.sigmoid(torch.tensor(result['score'])).item()\n",
        "    print(f\"\\nRank: {result['corpus_id'] + 1}\")\n",
        "    print(f\"Probability: {prob:.4f}\")\n",
        "    print(f\"Text: {result['text']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SCRIPT COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-17T14:25:07.233818Z",
          "iopub.execute_input": "2025-11-17T14:25:07.234146Z",
          "iopub.status.idle": "2025-11-17T14:25:07.527843Z",
          "shell.execute_reply.started": "2025-11-17T14:25:07.234122Z",
          "shell.execute_reply": "2025-11-17T14:25:07.527242Z"
        },
        "id": "8gqBv0-ZbRLE",
        "outputId": "13f2cf5d-3127-48a3-a536-c26bb93c303e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n================================================================================\nINFERENCE EXAMPLE\n================================================================================\n\nQuery:\n  cell_type: C_BEST4; tissue: descending colon; organism: Homo sapiens\n\nRanking candidates...\n\nRanked Results:\n\n1. Probability: 0.5016\n   Candidate: label: epithelial cell of colon; synonyms: colon epithelial cell; definition: An epithelial cell that is part of the colon.\n\n2. Probability: 0.5001\n   Candidate: label: smooth muscle fiber of descending colon; synonyms: non-striated muscle fiber of descending colon; definition: A smooth muscle cell that is part of the descending colon.\n\n3. Probability: 0.5001\n   Candidate: label: smooth muscle cell of colon; synonyms: non-striated muscle fiber of colon; definition: A smooth muscle cell that is part of the colon.\n\n================================================================================\nBATCH RANKING WITH model.rank()\n================================================================================\n\nTop 3 ranked results using model.rank():\n\nRank: 3\nProbability: 0.5016\nText: label: epithelial cell of colon; synonyms: colon epithelial cell; definition: An epithelial cell that is part of the colon.\n\nRank: 1\nProbability: 0.5001\nText: label: smooth muscle fiber of descending colon; synonyms: non-striated muscle fiber of descending colon; definition: A smooth muscle cell that is part of the descending colon.\n\nRank: 2\nProbability: 0.5001\nText: label: smooth muscle cell of colon; synonyms: non-striated muscle fiber of colon; definition: A smooth muscle cell that is part of the colon.\n\n================================================================================\nSCRIPT COMPLETED SUCCESSFULLY\n================================================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "VQQJg3CNbRLF"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}